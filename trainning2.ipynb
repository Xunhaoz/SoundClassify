{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:08.383593Z",
     "start_time": "2023-04-29T10:32:59.630655Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from rich.progress import track\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:08.397195Z",
     "start_time": "2023-04-29T10:33:08.386701Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "parameters = {\n",
    "    \"num_class\": 5,\n",
    "    \"time\": str(datetime.now()).replace(\" \", \"_\"),\n",
    "    \"model_name\": 'CNN',\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 16,\n",
    "    \"dropout\": 0.1,\n",
    "    \"wandb\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.547095Z",
     "start_time": "2023-04-29T10:33:08.399199Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxunhaoz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leo20\\Desktop\\TBrain\\wandb\\run-20230429_103311-hl121575</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xunhaoz/CNN1D/runs/hl121575' target=\"_blank\">peachy-plasma-22</a></strong> to <a href='https://wandb.ai/xunhaoz/CNN1D' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xunhaoz/CNN1D' target=\"_blank\">https://wandb.ai/xunhaoz/CNN1D</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xunhaoz/CNN1D/runs/hl121575' target=\"_blank\">https://wandb.ai/xunhaoz/CNN1D/runs/hl121575</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def init_wandb():\n",
    "    # start a new wandb run to track this script\n",
    "    parameters[\"wandb\"] = True\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"CNN1D\",\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"architecture\": \"CNN\",\n",
    "            \"dataset\": \"TBRAIN\",\n",
    "            \"epochs\": parameters['epochs'],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.568283Z",
     "start_time": "2023-04-29T10:33:13.548265Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_new_data(df_source_path=\"./Training Dataset/training datalist.csv\", df_dest_path=\"./NewGenData/NewGenData.csv\",\n",
    "                 dest=\"./NewGenData/voice\"):\n",
    "    \"\"\"\n",
    "    資料擴增，將所有音檔切成每段0.5秒\n",
    "    \"\"\"\n",
    "    all_df = pd.read_csv(df_source_path)\n",
    "    source_path = \"./Training Dataset/training_voice_data\"\n",
    "    dest_path = dest\n",
    "\n",
    "    expand_data = []\n",
    "    count = 5000\n",
    "\n",
    "    for row in all_df.iterrows():\n",
    "        waveform, sample_rate = torchaudio.load(os.path.join(source_path, row[1][\"ID\"] + \".wav\"))\n",
    "\n",
    "        chunks = None\n",
    "        if waveform.size(1) / sample_rate == 1:\n",
    "            chunks = torch.chunk(waveform, 2, dim=1)\n",
    "        elif waveform.size(1) / sample_rate == 1.5:\n",
    "            chunks = torch.chunk(waveform, 3, dim=1)\n",
    "        elif waveform.size(1) / sample_rate == 2:\n",
    "            chunks = torch.chunk(waveform, 4, dim=1)\n",
    "        elif waveform.size(1) / sample_rate == 3:\n",
    "            chunks = torch.chunk(waveform, 6, dim=1)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            count += 1\n",
    "            row[1][\"ID\"] = str(count) + \".wav\"\n",
    "            torchaudio.save(os.path.join(dest_path, row[1][\"ID\"]), chunk, sample_rate)\n",
    "            expand_data.append(row[1].copy())\n",
    "\n",
    "    expand_df = pd.concat(expand_data, axis=1, ignore_index=True)\n",
    "    expand_df.T.to_csv(df_dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.587464Z",
     "start_time": "2023-04-29T10:33:13.565379Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_new_data(source=\"NewGenData/NewGenData.csv\", train_dest=\"NewGenData/train_df.csv\",\n",
    "                   val_dest=\"NewGenData/val_df.csv\"):\n",
    "    \"\"\"\n",
    "    資料分割，確保所有類別資料被分為 0.8 0.2\n",
    "    \"\"\"\n",
    "    all_df = pd.read_csv(source)\n",
    "    cat1_df = all_df[all_df[\"Disease category\"] == 1]\n",
    "    cat2_df = all_df[all_df[\"Disease category\"] == 2]\n",
    "    cat3_df = all_df[all_df[\"Disease category\"] == 3]\n",
    "    cat4_df = all_df[all_df[\"Disease category\"] == 4]\n",
    "    cat5_df = all_df[all_df[\"Disease category\"] == 5]\n",
    "    train_cat1_df, val_cat1_df = train_test_split(cat1_df, train_size=0.8)\n",
    "    train_cat2_df, val_cat2_df = train_test_split(cat2_df, train_size=0.8)\n",
    "    train_cat3_df, val_cat3_df = train_test_split(cat3_df, train_size=0.8)\n",
    "    train_cat4_df, val_cat4_df = train_test_split(cat4_df, train_size=0.8)\n",
    "    train_cat5_df, val_cat5_df = train_test_split(cat5_df, train_size=0.8)\n",
    "\n",
    "    train_df = pd.concat([train_cat1_df, train_cat2_df, train_cat3_df, train_cat4_df, train_cat5_df],\n",
    "                         ignore_index=True).fillna(0)\n",
    "    val_df = pd.concat([val_cat1_df, val_cat2_df, val_cat3_df, val_cat4_df, val_cat5_df], ignore_index=True).fillna(0)\n",
    "\n",
    "    train_df.to_csv(train_dest)\n",
    "    val_df.to_csv(val_dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.624568Z",
     "start_time": "2023-04-29T10:33:13.588475Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, args, voice_path=\"NewGenData/voice\"):\n",
    "        self.df = df\n",
    "        self.voice_path = voice_path\n",
    "        self.num_class = args[\"num_class\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def one_hot_label(self, label):\n",
    "        return nn.functional.one_hot(torch.tensor(label - 1), num_classes=self.num_class)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pop_list = ['Unnamed: 0.1', 'Unnamed: 0', 'ID', 'Disease category']\n",
    "        pow_2_15 = 32768\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(\n",
    "            os.path.join(self.voice_path, self.df[\"ID\"][index])\n",
    "        )\n",
    "        label = self.df[\"Disease category\"][index]\n",
    "\n",
    "        table_info = self.df.iloc[index].copy().to_dict()\n",
    "        for pop_item in pop_list:\n",
    "            table_info.pop(pop_item)\n",
    "\n",
    "        \"\"\"擴展16倍\"\"\"\n",
    "        extend_list_info = []\n",
    "        for item in list(table_info.values()):\n",
    "            extend_list_info.extend([item] * 16)\n",
    "\n",
    "        waveform = torch.cat((waveform.view(-1), torch.tensor(extend_list_info)))\n",
    "        padding = (pow_2_15 - waveform.size(0))\n",
    "        waveform = nn.functional.pad(waveform, (padding // 2, padding - (padding // 2)), mode='constant', value=0)\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        return waveform, self.one_hot_label(label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.638602Z",
     "start_time": "2023-04-29T10:33:13.625074Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"記得接softmax\"\"\"\n",
    "\"\"\"one hot encoding 距離權重\"\"\"\n",
    "\n",
    "\n",
    "class SoundClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(parameters[\"dropout\"])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 256, 16 * 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16 * 256, 2 * 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * 256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, parameters[\"num_class\"]),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoundClassifierSmaller(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(parameters[\"dropout\"])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 4096, 2 ** 9),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 ** 9, 2 ** 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 ** 4, parameters[\"num_class\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoundClassifierFewer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(parameters[\"dropout\"])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 256, 4 * 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * 256, 2 * 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * 256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, parameters[\"num_class\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FromKaggle1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(parameters[\"dropout\"])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 8192, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, parameters[\"num_class\"]),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.670629Z",
     "start_time": "2023-04-29T10:33:13.640612Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pred(output):\n",
    "    return torch.argmax(output, dim=1)\n",
    "\n",
    "\n",
    "# calculate confusion metrics\n",
    "def cal_acc(pred, ans):\n",
    "    pred = get_pred(pred).cpu().numpy()\n",
    "    ans = get_pred(ans).cpu().numpy()\n",
    "    accuracy = accuracy_score(ans, pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.676984Z",
     "start_time": "2023-04-29T10:33:13.657749Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, loss_fct):\n",
    "    step_count = val_loss = val_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(inputs)\n",
    "            loss = loss_fct(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += cal_acc(logits, labels)\n",
    "            step_count += 1\n",
    "\n",
    "        val_loss = val_loss / step_count\n",
    "        val_acc = val_acc / step_count\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.686356Z",
     "start_time": "2023-04-29T10:33:13.673632Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, device, loss_fct, optimizer):\n",
    "    step_count = train_loss = train_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += cal_acc(logits, labels)\n",
    "        step_count += 1\n",
    "\n",
    "    train_loss = train_loss / step_count\n",
    "    train_acc = train_acc / step_count\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:13.720583Z",
     "start_time": "2023-04-29T10:33:13.688506Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"NewGenData1/train_df.csv\")\n",
    "vel_df = pd.read_csv(\"NewGenData1/val_df.csv\")\n",
    "\n",
    "train_dataset = AudioDataset(train_df, parameters, voice_path=\"NewGenData1/voice\")\n",
    "dev_dataset = AudioDataset(vel_df, parameters, voice_path=\"NewGenData1/voice\")\n",
    "\n",
    "train_dataLoader = DataLoader(train_dataset, batch_size=parameters[\"batch_size\"], shuffle=True)\n",
    "dev_dataLoader = DataLoader(dev_dataset, batch_size=parameters[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T10:33:14.543477Z",
     "start_time": "2023-04-29T10:33:13.719370Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SoundClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=parameters['learning_rate'], momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=parameters['learning_rate'], betas=(0.9, 0.999), eps=1e-9)\n",
    "loss_fct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T07:18:33.470748Z",
     "start_time": "2023-04-29T00:53:29.513612Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] cost time: 21.9150 s\n",
      "         loss        acc\n",
      "train |  1.6126,\t 0.1946\n",
      "val   |  1.6074,\t 0.2245\n",
      "\n",
      "[epoch 2] cost time: 13.3580 s\n",
      "         loss        acc\n",
      "train |  1.6012,\t 0.2313\n",
      "val   |  1.5954,\t 0.2245\n",
      "\n",
      "[epoch 3] cost time: 13.3749 s\n",
      "         loss        acc\n",
      "train |  1.5891,\t 0.5138\n",
      "val   |  1.5822,\t 0.5724\n",
      "\n",
      "[epoch 4] cost time: 13.5617 s\n",
      "         loss        acc\n",
      "train |  1.5753,\t 0.5583\n",
      "val   |  1.5672,\t 0.5700\n",
      "\n",
      "[epoch 5] cost time: 13.5553 s\n",
      "         loss        acc\n",
      "train |  1.5594,\t 0.5565\n",
      "val   |  1.5488,\t 0.5700\n",
      "\n",
      "[epoch 6] cost time: 13.5354 s\n",
      "         loss        acc\n",
      "train |  1.5390,\t 0.5586\n",
      "val   |  1.5261,\t 0.5651\n",
      "\n",
      "[epoch 7] cost time: 13.7013 s\n",
      "         loss        acc\n",
      "train |  1.5107,\t 0.5576\n",
      "val   |  1.4893,\t 0.5627\n",
      "\n",
      "[epoch 8] cost time: 13.5785 s\n",
      "         loss        acc\n",
      "train |  1.4561,\t 0.5576\n",
      "val   |  1.4088,\t 0.5627\n",
      "\n",
      "[epoch 9] cost time: 14.0470 s\n",
      "         loss        acc\n",
      "train |  1.3761,\t 0.5569\n",
      "val   |  1.3498,\t 0.5651\n",
      "\n",
      "[epoch 10] cost time: 13.7627 s\n",
      "         loss        acc\n",
      "train |  1.3535,\t 0.5569\n",
      "val   |  1.3456,\t 0.5627\n",
      "\n",
      "[epoch 11] cost time: 13.4171 s\n",
      "         loss        acc\n",
      "train |  1.3496,\t 0.5576\n",
      "val   |  1.3416,\t 0.5651\n",
      "\n",
      "[epoch 12] cost time: 13.3668 s\n",
      "         loss        acc\n",
      "train |  1.3500,\t 0.5562\n",
      "val   |  1.3361,\t 0.5700\n",
      "\n",
      "[epoch 13] cost time: 13.5542 s\n",
      "         loss        acc\n",
      "train |  1.3485,\t 0.5572\n",
      "val   |  1.3382,\t 0.5676\n",
      "\n",
      "[epoch 14] cost time: 13.7683 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5572\n",
      "val   |  1.3380,\t 0.5676\n",
      "\n",
      "[epoch 15] cost time: 13.7512 s\n",
      "         loss        acc\n",
      "train |  1.3488,\t 0.5565\n",
      "val   |  1.3378,\t 0.5676\n",
      "\n",
      "[epoch 16] cost time: 13.9504 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5572\n",
      "val   |  1.3353,\t 0.5700\n",
      "\n",
      "[epoch 17] cost time: 13.6271 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5569\n",
      "val   |  1.3401,\t 0.5651\n",
      "\n",
      "[epoch 18] cost time: 14.0540 s\n",
      "         loss        acc\n",
      "train |  1.3479,\t 0.5572\n",
      "val   |  1.3376,\t 0.5676\n",
      "\n",
      "[epoch 19] cost time: 14.1431 s\n",
      "         loss        acc\n",
      "train |  1.3468,\t 0.5583\n",
      "val   |  1.3400,\t 0.5651\n",
      "\n",
      "[epoch 20] cost time: 14.0036 s\n",
      "         loss        acc\n",
      "train |  1.3471,\t 0.5579\n",
      "val   |  1.3351,\t 0.5700\n",
      "\n",
      "[epoch 21] cost time: 13.5238 s\n",
      "         loss        acc\n",
      "train |  1.3478,\t 0.5572\n",
      "val   |  1.3423,\t 0.5627\n",
      "\n",
      "[epoch 22] cost time: 14.1093 s\n",
      "         loss        acc\n",
      "train |  1.3467,\t 0.5583\n",
      "val   |  1.3423,\t 0.5627\n",
      "\n",
      "[epoch 23] cost time: 13.3692 s\n",
      "         loss        acc\n",
      "train |  1.3478,\t 0.5572\n",
      "val   |  1.3375,\t 0.5676\n",
      "\n",
      "[epoch 24] cost time: 13.5045 s\n",
      "         loss        acc\n",
      "train |  1.3488,\t 0.5562\n",
      "val   |  1.3423,\t 0.5627\n",
      "\n",
      "[epoch 25] cost time: 14.0515 s\n",
      "         loss        acc\n",
      "train |  1.3481,\t 0.5569\n",
      "val   |  1.3399,\t 0.5651\n",
      "\n",
      "[epoch 26] cost time: 13.6839 s\n",
      "         loss        acc\n",
      "train |  1.3467,\t 0.5583\n",
      "val   |  1.3350,\t 0.5700\n",
      "\n",
      "[epoch 27] cost time: 13.3824 s\n",
      "         loss        acc\n",
      "train |  1.3474,\t 0.5576\n",
      "val   |  1.3423,\t 0.5627\n",
      "\n",
      "[epoch 28] cost time: 13.4884 s\n",
      "         loss        acc\n",
      "train |  1.3484,\t 0.5565\n",
      "val   |  1.3374,\t 0.5676\n",
      "\n",
      "[epoch 29] cost time: 13.5315 s\n",
      "         loss        acc\n",
      "train |  1.3474,\t 0.5576\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 30] cost time: 13.2619 s\n",
      "         loss        acc\n",
      "train |  1.3474,\t 0.5576\n",
      "val   |  1.3374,\t 0.5676\n",
      "\n",
      "[epoch 31] cost time: 13.3438 s\n",
      "         loss        acc\n",
      "train |  1.3470,\t 0.5579\n",
      "val   |  1.3471,\t 0.5579\n",
      "\n",
      "[epoch 32] cost time: 13.6029 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 33] cost time: 13.5232 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3374,\t 0.5676\n",
      "\n",
      "[epoch 34] cost time: 13.3608 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 35] cost time: 13.3491 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 36] cost time: 13.4729 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3374,\t 0.5676\n",
      "\n",
      "[epoch 37] cost time: 13.2767 s\n",
      "         loss        acc\n",
      "train |  1.3463,\t 0.5586\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 38] cost time: 13.2740 s\n",
      "         loss        acc\n",
      "train |  1.3470,\t 0.5579\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 39] cost time: 13.3149 s\n",
      "         loss        acc\n",
      "train |  1.3477,\t 0.5572\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 40] cost time: 13.7490 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 41] cost time: 13.5520 s\n",
      "         loss        acc\n",
      "train |  1.3484,\t 0.5565\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 42] cost time: 13.2169 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3325,\t 0.5724\n",
      "\n",
      "[epoch 43] cost time: 13.3716 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 44] cost time: 13.4768 s\n",
      "         loss        acc\n",
      "train |  1.3459,\t 0.5590\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 45] cost time: 13.6054 s\n",
      "         loss        acc\n",
      "train |  1.3477,\t 0.5572\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 46] cost time: 13.4852 s\n",
      "         loss        acc\n",
      "train |  1.3477,\t 0.5572\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 47] cost time: 14.3257 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3398,\t 0.5651\n",
      "\n",
      "[epoch 48] cost time: 13.4878 s\n",
      "         loss        acc\n",
      "train |  1.3462,\t 0.5586\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 49] cost time: 13.6552 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 50] cost time: 13.5856 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 51] cost time: 13.6676 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 52] cost time: 13.4536 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 53] cost time: 13.8478 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 54] cost time: 13.8376 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 55] cost time: 13.6189 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 56] cost time: 13.3745 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 57] cost time: 13.3437 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 58] cost time: 13.2633 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 59] cost time: 13.7013 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 60] cost time: 13.9447 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 61] cost time: 14.3930 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 62] cost time: 13.4686 s\n",
      "         loss        acc\n",
      "train |  1.3491,\t 0.5558\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 63] cost time: 13.2765 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 64] cost time: 13.3813 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3470,\t 0.5579\n",
      "\n",
      "[epoch 65] cost time: 13.3264 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3422,\t 0.5627\n",
      "\n",
      "[epoch 66] cost time: 13.3896 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 67] cost time: 13.3297 s\n",
      "         loss        acc\n",
      "train |  1.3490,\t 0.5558\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 68] cost time: 13.3702 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 69] cost time: 14.1764 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 70] cost time: 14.1196 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3325,\t 0.5724\n",
      "\n",
      "[epoch 71] cost time: 13.4636 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 72] cost time: 13.4229 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 73] cost time: 13.4976 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 74] cost time: 13.8733 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3325,\t 0.5724\n",
      "\n",
      "[epoch 75] cost time: 13.4637 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 76] cost time: 13.7614 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 77] cost time: 13.5487 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 78] cost time: 13.2216 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 79] cost time: 13.3097 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 80] cost time: 13.2804 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3470,\t 0.5579\n",
      "\n",
      "[epoch 81] cost time: 13.6222 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 82] cost time: 13.7969 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 83] cost time: 13.5299 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 84] cost time: 13.3894 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 85] cost time: 13.5304 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 86] cost time: 13.3227 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 87] cost time: 13.7461 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 88] cost time: 13.2606 s\n",
      "         loss        acc\n",
      "train |  1.3490,\t 0.5558\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 89] cost time: 13.3015 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 90] cost time: 13.2442 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 91] cost time: 13.2639 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 92] cost time: 13.2617 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 93] cost time: 13.3109 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3470,\t 0.5579\n",
      "\n",
      "[epoch 94] cost time: 13.6122 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 95] cost time: 13.7725 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 96] cost time: 13.3033 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 97] cost time: 13.2604 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3325,\t 0.5724\n",
      "\n",
      "[epoch 98] cost time: 13.2832 s\n",
      "         loss        acc\n",
      "train |  1.3459,\t 0.5590\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 99] cost time: 13.4056 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 100] cost time: 13.4834 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3470,\t 0.5579\n",
      "\n",
      "[epoch 101] cost time: 13.6460 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3325,\t 0.5724\n",
      "\n",
      "[epoch 102] cost time: 13.6119 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 103] cost time: 13.8168 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 104] cost time: 13.3983 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 105] cost time: 13.5674 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 106] cost time: 13.5785 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 107] cost time: 13.5141 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 108] cost time: 13.4285 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 109] cost time: 13.3799 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 110] cost time: 13.4311 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 111] cost time: 13.3858 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 112] cost time: 13.2880 s\n",
      "         loss        acc\n",
      "train |  1.3494,\t 0.5555\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 113] cost time: 13.3028 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 114] cost time: 13.5480 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 115] cost time: 13.8368 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 116] cost time: 13.7872 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 117] cost time: 13.4376 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 118] cost time: 13.5391 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 119] cost time: 13.4406 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 120] cost time: 13.4282 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 121] cost time: 13.3403 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 122] cost time: 13.3611 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3470,\t 0.5579\n",
      "\n",
      "[epoch 123] cost time: 13.3392 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 124] cost time: 13.4655 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 125] cost time: 13.2958 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 126] cost time: 13.3178 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 127] cost time: 13.3612 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 128] cost time: 13.5839 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 129] cost time: 13.2994 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 130] cost time: 13.2028 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 131] cost time: 13.2159 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 132] cost time: 13.1587 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 133] cost time: 13.1630 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3494,\t 0.5555\n",
      "\n",
      "[epoch 134] cost time: 13.1937 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 135] cost time: 13.2539 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 136] cost time: 13.9100 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 137] cost time: 13.5958 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 138] cost time: 13.1792 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 139] cost time: 13.2117 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 140] cost time: 13.9982 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3349,\t 0.5700\n",
      "\n",
      "[epoch 141] cost time: 14.5665 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 142] cost time: 13.2217 s\n",
      "         loss        acc\n",
      "train |  1.3466,\t 0.5583\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 143] cost time: 13.2539 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 144] cost time: 13.2606 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 145] cost time: 13.7319 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 146] cost time: 13.6033 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 147] cost time: 13.2826 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 148] cost time: 13.6519 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 149] cost time: 13.4663 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 150] cost time: 13.6735 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 151] cost time: 13.6239 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3446,\t 0.5603\n",
      "\n",
      "[epoch 152] cost time: 13.3484 s\n",
      "         loss        acc\n",
      "train |  1.3490,\t 0.5558\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n",
      "[epoch 153] cost time: 13.2487 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 154] cost time: 13.2815 s\n",
      "         loss        acc\n",
      "train |  1.3480,\t 0.5569\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 155] cost time: 13.7020 s\n",
      "         loss        acc\n",
      "train |  1.3473,\t 0.5576\n",
      "val   |  1.3373,\t 0.5676\n",
      "\n",
      "[epoch 156] cost time: 13.5498 s\n",
      "         loss        acc\n",
      "train |  1.3469,\t 0.5579\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 157] cost time: 13.6617 s\n",
      "         loss        acc\n",
      "train |  1.3483,\t 0.5565\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 158] cost time: 13.6740 s\n",
      "         loss        acc\n",
      "train |  1.3487,\t 0.5562\n",
      "val   |  1.3421,\t 0.5627\n",
      "\n",
      "[epoch 159] cost time: 14.3063 s\n",
      "         loss        acc\n",
      "train |  1.3476,\t 0.5572\n",
      "val   |  1.3397,\t 0.5651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(parameters[\"epochs\"]):\n",
    "    st_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_dataLoader, device, loss_fct, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, dev_dataLoader, device, loss_fct)\n",
    "\n",
    "    print('[epoch %d] cost time: %.4f s' % (epoch + 1, time.time() - st_time))\n",
    "    print('         loss        acc')\n",
    "    print(f'train | {train_loss: .4f},\\t{train_acc: .4f}')\n",
    "    print(f'val   | {val_loss: .4f},\\t{val_acc: .4f}\\n')\n",
    "    if parameters[\"wandb\"]:\n",
    "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"test_acc\": val_acc, \"test_loss\": val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T07:18:33.501200Z",
     "start_time": "2023-04-29T07:18:33.474749Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
